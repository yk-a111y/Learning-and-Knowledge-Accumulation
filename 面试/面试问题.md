## Python相关
### Python的数据类型
![[Pasted image 20250401165826.png]]
### Python数据类型判断
![[Pasted image 20250401165935.png]]
### Python 中 `list`、`tuple`、`set` 的底层数据结构是什么？为什么 `tuple` 比 `list` 更快？
list（动态数组，类似 C++ vector）
底层基于 可变数组（动态数组），预分配一定空间，动态扩容时 时间复杂度 O(n)。

tuple（不可变数组）
结构固定，不需要额外存储可变信息，访问速度比 list 快。

tuple 可作为字典的 key，而 list 不能（因为 tuple 是 可哈希的）。

set（哈希表）

去重和快速查找，底层基于 哈希表（dict），查询时间复杂度 O(1)。

```python
my_list = [1, 2, 3]    # 动态数组
my_tuple = (1, 2, 3)   # 静态数组（优化存储）
my_set = {1, 2, 3}     # 哈希表（去重）
```
### Python `dict` 的底层实现是什么？为什么字典查询比列表快？
- **字典（dict）使用哈希表（Hash Table）实现**，查找时间复杂度 **O(1)**。
- **列表（list）使用数组存储，查找需要 O(n)**
- **dict 使用开放地址法解决哈希冲突**，Python 3.6+ 采用 **有序字典（OrderedDict）**。开放地址法的核心思想是：当发生哈希冲突时，通过某种探测(probing)策略在哈希表中寻找其他空闲位置来存储元素
### Python的GC机制是如何的？
Python 使用 **引用计数（Reference Counting）** 作为主要回收机制
当 **引用数降为 0** 时，Python 释放对象
**循环引用** 通过 **垃圾回收器（GC，Generational GC）** 处理
## LangChain 源码相关
### 解释 LangChain 的核心组件及它们如何交互构建 LLM 应用？
LangChain 由以下核心组件组成:
#### 1. 模型 (Models)

- LLM 封装器：标准化接口访问 OpenAI、Anthropic、Hugging Face 等提供商的大语言模型

- 嵌入模型：将文本转换为向量表示，支持语义搜索和相似度比较

- 聊天模型：特别针对对话式交互进行了优化的模型接口

- 文本生成器：提供统一的接口生成文本，无论底层模型类型如何

#### 2. 提示 (Prompts)

- 提示模板：参数化文本模板，可插入变量创建动态提示

- 示例选择器：根据用户输入智能选择最相关的少样本学习示例

- 输出解析器：将 LLM 输出转换为结构化数据（JSON、列表等）

- 提示管理：版本控制和提示模板库管理功能

#### 3. 记忆 (Memory)

- 对话记忆：存储交互历史，包括聊天消息缓冲区、摘要和窗口缓冲区

- 向量存储记忆：使用嵌入保存对话历史，可按相关性检索

- 实体记忆：跟踪和更新对话中提及的实体信息

- 短期/长期记忆：区分处理即时上下文和长期保存的信息

#### 4. 链 (Chains)

- LLM链：最基本的链，将提示传递给LLM并处理输出

- 顺序链：按特定顺序执行多个链，前一链的输出成为下一链的输入

- 路由链：根据输入内容决定使用哪条链路

- 转换链：处理和修改数据（如提取、摘要、翻译）

- 检索增强链：根据用户查询从外部获取信息后再生成回答

- 问答链：专门用于问答系统的专用链结构
#### 5. 代理 (Agents)

- ReAct代理：综合推理和行动能力的代理

- 工具使用代理：能够选择和调用外部工具的代理

- 计划和执行代理：先计划行动步骤再执行的代理

- OpenAI函数代理：利用OpenAI函数调用功能的专用代理

- 自反代理：具有自我评估和改进能力的代理

- 多代理系统：协作解决任务的代理集合

#### 6. 工具 (Tools)

- 搜索工具：连接Google、Bing等搜索引擎

- API工具：封装REST API调用功能

- 文件操作工具：读写文件系统的能力

- 数据库工具：连接和查询数据库

- 代码解释器：执行Python代码的工具

- 自定义工具：可扩展的自定义功能接口

#### 7. 检索器 (Retrievers)

- 向量存储检索器：基于相似度从向量数据库获取文档

- 多查询检索器：生成多个变体查询以提高召回率

- 上下文压缩器：对检索内容进行过滤和优化

- 自查询检索器：能够自动转换用户查询以优化检索效果

- 合并检索器：组合多种检索策略结果

- 重排序检索器：对检索到的文档进行二次排序

#### 8. 索引与存储 (Indexes & Storage)

- 文档加载器：从各种源（PDF、网页、数据库等）加载文档

- 文本分割器：将长文本分割成适合处理的小块

- 向量存储：存储和检索文本嵌入（如Chroma、FAISS、Pinecone）

- 文档转换器：预处理文档以提高检索质量
#### 9. 数据连接器 (Data Connectors)

- 结构化数据连接器：连接数据库、CSV、JSON等

- 非结构化数据连接器：处理文档、图像等

- API集成：连接第三方服务和平台

- 文档处理管道：完整的数据处理和索引流程
这些组件以模块化方式交互。例如，典型的 RAG 应用使用检索器获取上下文，提示模板格式化用户查询，模型生成响应，链协调整个流程。

### 描述 LangChain 和 LangGraph 的区别。何时使用一个而非另一个？
LangChain 提供组件用于以线性、顺序方式构建 LLM 应用。LangGraph 扩展了 LangChain，支持复杂的循环工作流和状态管理。

使用 LangChain 适合:

- 简单的顺序处理

- 基础 RAG 应用

- 直接的操作链

使用 LangGraph 适合:

- 需要协调的多代理系统

- 需要迭代优化循环的应用

- 带条件分支的复杂工作流

- 需要跨迭代持久状态的系统

当需要状态机和基于图的流程而非线性管道时，LangGraph 是理想选择
### 如何使用 LlamaIndex 实现检索增强生成(RAG)系统
加载文档:
```python
from llama_index import SimpleDirectoryReader
documents = SimpleDirectoryReader("data").load_data()
```
....
### 解释如何调试和优化产生不准确结果的 LangChain 应用
1. 启用详细日志跟踪执行:
2. 提示工程 - 优化指令和示例
3. 通过独立测试隔离组件:
- 使用原始提示测试 LLM 响应
- 单独验证检索器结果
- 检查交互间的内存状态
4. 改进检索:

- 调整分块策略
- 使用更好的嵌入模型
- 添加重排序步骤

5. 实现自验证:

- 带验证的结构化输出
- 多步推理
- 反馈循环
## 项目 & 实习相关
### Redis缓存
#### Redis 的持久化方式有哪些？它们有什么区别？
6. RDB（Redis Database）

- 原理：某个时间点对数据进行快照存储

- 优点：

- 文件紧凑，适合备份

- 恢复速度快

- 缺点：

- 可能丢失最后一次快照后的数据

- fork 子进程时可能会阻塞服务

7. AOF（Append Only File）

- 原理：记录所有写操作命令

- 优点：

- 数据安全性高

- 可以处理误操作

- 缺点：

- 文件体积较大

- 恢复速度较慢
#### Redis过期删除策略和内存淘汰机制是什么
**过期删除策略：**
定期删除：每隔一段时间随机抽取一些设置了过期时间的 key 进行检查和删除
惰性删除：只有当访问一个 key 时，才会判断是否过期，过期则删除
**内存淘汰机制：**
noeviction：不删除，写入报错
allkeys-lru：最近最少使用的数据淘汰
volatile-lru：设置了过期时间的键中，最近最少使用的数据淘汰
allkeys-random：随机淘汰数据
volatile-random：设置了过期时间的键中，随机淘汰
volatile-ttl：设置了过期时间的键中，优先淘汰更早过期的数据

#### 解决缓存雪崩、缓存穿透和缓存击穿问题
缓存雪崩
- 原因：大量缓存同时失效
 解决方案：
- 设置不同的过期时间
- 使用熔断机制
- 提高系统可用性

缓存穿透
- 原因：查询不存在的数据
 解决方案：
- 布隆过滤器
- 缓存空值
- 参数校验

缓存击穿
- 原因：热点 key 过期
 解决方案：
- 互斥锁
- 永不过期
- 提前更新
### 雪花算法
雪花算法（Snowflake）是一种 分布式 ID 生成算法，最早由 Twitter 开发，用于生成 全局唯一、高性能、趋势递增 的 64-bit 整型 ID，广泛应用于 数据库主键、分布式系统、消息队列等 场景
![[Pasted image 20250403142629.png]]
![[Pasted image 20250403142708.png]]
### 延时队列
![[Pasted image 20250403143224.png]]
![[Pasted image 20250403143247.png]]
### 分表技术
![[Pasted image 20250403144422.png]]
![[Pasted image 20250403144443.png]]
![[Pasted image 20250403144509.png]]
![[Pasted image 20250403144520.png]]
![[Pasted image 20250403144545.png]]
### RAG
利用一个检索模块从外部知识库中取回相关信息，作为上下文提供给大语言模型（如 GPT），再由模型根据这些信息生成答案。
![[Pasted image 20250407104140.png]]
**常见组成：**
Query Encoder：将问题转换为向量（语义表示）
Dense Vector Retriever（向量检索）：例如 FAISS、Elasticsearch、Milvus 等，用于在知识库中快速找相关段落
Prompt 构建器：将问题 + 检索内容合并成提示词
LLM 生成器：使用 GPT、T5、ChatGLM 等模型来生成回答

RAG 的挑战与优化方向

| 问题             | 说明                       |
| -------------- | ------------------------ |
| **文档分块粒度**     | 太小会丢失上下文，太大可能导致上下文超限     |
| **Top-k 检索不准** | 向量召回不准会误导生成              |
| **生成可信度**      | 模型有可能编造（hallucination）内容 |
| **多轮对话支持弱**    | 多轮时需要保留历史对话与检索历史         |

![[Pasted image 20250407104325.png]]
### 向量检索的优化
#### 1. 文档分块（chunking）策略优化

- **推荐做法**：
    
    - 控制 chunk 长度在 **300~500 tokens**（避免太短或太长）
        
    - 尽量按照**语义边界**切分，如按标题/段落分
        
    - 使用滑窗策略（sliding window），提高覆盖度
        
        python
        
        复制编辑
        
        `chunk_size = 500 overlap = 100`
        
- 工具：`LangChain` 中 `RecursiveCharacterTextSplitter`

#### 2. 增加元数据（metadata）

为每个 chunk 添加标签、来源、所属模块、页面位置等信息，方便后续重排序和过滤。
#### 3. 使用高质量 Embedding 模型
- 推荐模型：
    
    - 英文：`text-embedding-ada-002`（OpenAI），`E5`，`Instructor`
        
    - 中文：`BGE-large-zh`，`text2vec-base-chinese`
        
    - 多语言：`LaBSE`, `distiluse-base-multilingual`
        
- 注意点：
    
    - 模型风格要和任务匹配（问答式 vs 检索式）
        
    - 向量归一化（normalize）提高检索精度
#### 4. 问题嵌入增强
对 Query 做补充增强：

- 问题扩展（Query Expansion）
    
- 添加上下文（如角色、语气、历史对话）
    
- 加入问题类型判断（判断是“定义型”还是“比较型”等）

![[Pasted image 20250407104716.png]]
<font color="#d83931">当向量检索结果不相关或为空时，大模型就会“胡说八道”甚至产生 hallucination（幻觉）。</font>
### 大模型的训练过程
![[Pasted image 20250407105329.png]]
### 旋转位置编码（RoPE）的原理及优势
![[Pasted image 20250407105413.png]]
### 比较 Seq2Seq、Transformer 和 GPT 的结构和应用差异
![[Pasted image 20250407105501.png]]
### 解释卷积神经网络（CNN）的核心原理和应用流程
![[Pasted image 20250407105556.png]]
### Docker工作中用过什么， 写过Docker File吗
### Dify二次开发
## 算法题
### 两数之和
```python
# 输出：nums = [2,7,11,15], target = 9
# 输入：[0,1]
class Solution:
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        hashset={}
        for i in range(len(nums)):
            if hashset.get(target-nums[i]) is not None :
                return [hashset.get(target-nums[i]),i]
            hashset[nums[i]]=i
```
### 全排列
```python
# 输入：[1,2,3]
# 输出：[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1] ]
class Solution:
    def permute(self, nums):
        result = []
        self.backtracking(nums, [], [False] * len(nums), result)
        return result

    def backtracking(self, nums, path, used, result):
        if len(path) == len(nums):
            result.append(path[:])
            return
        for i in range(len(nums)):
            if used[i]:
                continue
            used[i] = True
            path.append(nums[i])
            self.backtracking(nums, path, used, result)
            path.pop()
            used[i] = False
```